{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# ELE510 Image Processing with robot vision: LAB, Exercise 2, Image Formation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**Purpose:** *To learn about the image formation process, i.e. how images are projected from the scene to the image plane.*\n",
    "\n",
    "The theory for this exercise can be found in chapter 2 and 3 of the text book [1]. Supplementary information can found in chapter 1, 2 and 3 in the compendium [2]. See also the following documentations for help:\n",
    "- [OpenCV](https://opencv.org/opencv-python-free-course/)\n",
    "- [numpy](https://numpy.org/doc/stable/)\n",
    "- [matplotlib](https://matplotlib.org/stable/contents.html)\n",
    "\n",
    "**IMPORTANT:** Read the text carefully before starting the work. In\n",
    "many cases it is necessary to do some preparations before you start the work\n",
    "on the computer. Read necessary theory and answer the theoretical part\n",
    "frst. The theoretical and experimental part should be solved individually.\n",
    "The notebook must be approved by the lecturer or his assistant.\n",
    "\n",
    "**Approval:**\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "The current notebook should be submitted on CANVAS as a single pdf file. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    To export the notebook in a pdf format, goes to File -> Download as -> PDF via LaTeX (.pdf).\n",
    "</div>\n",
    "\n",
    "**Note regarding the notebook**: The theoretical questions can be answered directly on the notebook using a *Markdown* cell and LaTex commands (if relevant). In alternative, you can attach a scan (or an image) of the answer directly in the cell.\n",
    "\n",
    "Possible ways to insert an image in the markdown cell:\n",
    "\n",
    "`![image name](\"image_path\")`\n",
    "\n",
    "`<img src=\"image_path\" alt=\"Alt text\" title=\"Title text\" />`\n",
    "\n",
    "\n",
    "**Under you will find parts of the solution that is already programmed.**\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>You have to fill out code everywhere it is indicated with `...`</p>\n",
    "    <p>The code section under `######## a)` is answering subproblem a) etc.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**a)** What is the meaning of the abbreviation PSF? What does the PSF specify?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PSF - Point Spread Function, more generally known as a systems impulse response, is a function that <br>\n",
    "describes how how an object will look like when processed by an imaging system. It specifies the <br>\n",
    "shape that a point will take on the image pane. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**b)** Use the imaging model shown in Figure 1. The camera has a lens with focal length $f = 40\\text{mm}$ and in the image plane a CCD sensor of size $8\\text{mm} \\times 8\\text{mm}$. The total number of pixels is $4000 \\times 4000$. How many lines per mm will this camera resolve at a distance of $z_w = 1\\text{m}$ from the camera center?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<img src=\"./images/perspectiveProjection.jpg\" alt=\"Alt text\" title=\"Title text\" />\n",
    "\n",
    "**Figure 1**: Perspective projection caused by a pinhole camera. Figure 2.23 in [2].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**c)** Explain how a Bayer filter works. What is the alternative to using this type of filter in image acquisition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayer filter is a sensor overlay (or color filter array) which is used to filter light wavelengths. \n",
    "The filter is arranged in a grid-like pattern, where half of the squares are used \n",
    "to sense green, one quarter to sense red and one quarter to sense blue.\n",
    "This method is a compromise between the cost of the sensor and the quality of the image, given that other methods such as using three sensors would be more expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## Problem 2\n",
    "\n",
    "Assume we have captured an image with a digital camera. The image covers an area in the scene of size $1.024\\text{m} \\times 0.768\\text{m}$ (The camera has been pointed towards a wall such that the distance is approximately constant over the whole image plane, *weak perspective*). The camera has 2048 pixels horizontally, and 1536 pixels vertically. The active region on the CCD-chip is $10\\text{mm} \\times 7.5\\text{mm}$. We define the spatial coordinates $(x_w,y_w)$ such that the origin is at the center of the optical axis, x-axis horizontally and y-axis vertically upwards. The image indexes $(x,y)$ is starting in the upper left corner. For simplicity let the optical axis meet the image plane at $(x_{0}=1024,y_{0}=768)$. The solutions to this problem can be found from simple geometric considerations. Make a sketch of the situation and answer the following questions:\n",
    "\n",
    "**a)** What is the size of each sensor (one pixel) on the CCD-chip?\n",
    "\n",
    "**b)** What is the scaling coefficient between the image plane (CCD-chip) and the scene? What is the scaling coefficient between the scene coordinates and the image indexes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./images/Page1.png\" alt=\"Alt text\" width=30% height=50% title=\"Title text\" />\n",
    "\n",
    "<img src=\"./images/Page2.png\" alt=\"Alt text\" width=30% title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## Problem 3\n",
    "\n",
    "Translation from the scene to a camera sensor can be done using a transformation matrix, $T$. \n",
    "\n",
    "\\begin{equation}\n",
    "\t\\begin{bmatrix} x\\\\y\\\\1\\end{bmatrix} = \n",
    "\tT\n",
    "\t\\begin{bmatrix}\n",
    "\t\tx_w\\\\ y_w\\\\ 1\n",
    "\t\\end{bmatrix}\\\\\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "\tT= \\begin{bmatrix} \\alpha_x & 0 & x_0\\\\\n",
    "\t\t\t0 & \\alpha_y & y_0\\\\\n",
    "\t\t0   & 0 & 1\n",
    "\t\\end{bmatrix}\n",
    "\\end{equation}\n",
    "$\\alpha_x$ and $\\alpha_y$ are the scaling factors for their corresponding axes.\n",
    "\n",
    "Write a function in Python that computes the image points using the transformation matrix, using the parameters from Problem 2. Let the input to the function be a set of $K$ scene points, given by a $2 \\times K$ matrix, and the output the resulting image points also given by a $2 \\times K$ matrix. The parameters defining the image sensor and field of view from the camera center to the wall can also be given as input parameters.\n",
    "\n",
    "Test the function for the following input points given as a matrix:\n",
    "\\begin{equation}\\label{cam-eq4}\n",
    "    {\\mathbf P}_{in} = \\begin{bmatrix} 0.512 & -0.512 & -0.512 & 0.512 & 0 & 0.3 & 0.3 & 0.3 & 0.6 \\\\\n",
    "    0.384 & 0.384 & -0.384 & -0.384 & 0 & 0.2 & -0.2 & -0.4 & 0 \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Comment on the results, especially notice the two last points!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages that are useful inside the definition of the weakPerspective function\n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that takes in input:\n",
    "- FOV: field of view,\n",
    "- sensorsize: size of the sensor,\n",
    "- n_pixels: camera pixels,\n",
    "- p_scene: K input points (2xK matrix)\n",
    "\n",
    "and return the resulting image points given the 2xK matrix\n",
    "\"\"\"\n",
    "def weakPerspective(FOV, sensorsize, n_pixels, p_scene):\n",
    "    \n",
    "    # scale = scene * sensor (coefficients)\n",
    "    scale = (sensorsize / FOV) * (FOV / n_pixels)\n",
    "    p_scene = np.vstack([p_scene, np.ones(p_scene.shape[1])])\n",
    "\n",
    "    T = np.array([[scale[0], 0, FOV[0]], [0, scale[1], FOV[1]], [0, 0, 1]])\n",
    "    res = np.round(T @ p_scene, 2)\n",
    "    res.dtype = 'float32'\n",
    "    return res\n",
    "\n",
    "def weakPerspective2(FOV, sensorsize, n_pixels, p_scene):\n",
    "    # pixel size\n",
    "    p_x, p_y = sensorsize[0] / n_pixels[0], sensorsize[1] / n_pixels[1]\n",
    "\n",
    "    # scale factors\n",
    "    a_x, a_y = sensorsize[0] / FOV[0], sensorsize[1] / FOV[1]\n",
    "    s_x, s_y = a_x / p_x, a_y / p_y\n",
    "    x_0, y_0 = n_pixels[0] / 2, n_pixels[1] / 2\n",
    "\n",
    "    # transformation matrix\n",
    "    T = np.array([[s_x, 0, x_0], [0, s_y, y_0], [0, 0, 1]])\n",
    "    coords = np.vstack([p_scene, np.ones((1, p_scene.shape[1]))])\n",
    "    return np.matmul(T, coords)[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above function is then called using the following parameters:\n",
    "\n",
    "# Parameters\n",
    "FOV = np.array([1.024, 0.768])\n",
    "sensorsize = np.array([10e-3, 7.5e-3])\n",
    "n_pixels = np.array([2048, 1536])\n",
    "p_scene_x = [0.512, -0.512, -0.512, 0.512, 0, 0.3, 0.3, 0.3, 0.6]\n",
    "p_scene_y = [0.384, 0.384, -0.384, -0.384, 0, 0.2, -0.2, -0.4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2048.    0.    0. 2048. 1024. 1624. 1624. 1624. 2224.]\n",
      " [1536. 1536.    0.    0.  768. 1168.  368.  -32.  768.]]\n"
     ]
    }
   ],
   "source": [
    "p_scene = np.array([p_scene_x, p_scene_y])\n",
    "\n",
    "# Call to the weakPerspective() function \n",
    "pimage = weakPerspective2(FOV, sensorsize, n_pixels, p_scene)\n",
    "\n",
    "# Result: \n",
    "print(pimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "\n",
    "### Delivery (dead line) on CANVAS: 16-09-2022 at 23:59\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Contact\n",
    "### Course teacher\n",
    "Professor Kjersti Engan, room E-431\n",
    "\n",
    "E-mail: kjersti.engan@uis.no\n",
    "\n",
    "### Teaching assistant\n",
    "Tomasetti Luca, room E-401\n",
    "E-mail: luca.tomasetti@uis.no\n",
    "\n",
    "\n",
    "Saul Fuster Navarro, room E-401\n",
    "E-mail: saul.fusternavarro@uis.no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## References\n",
    "\n",
    "[1] S. Birchfeld, Image Processing and Analysis. Cengage Learning, 2016.\n",
    "\n",
    "[2] I. Austvoll, \"Machine/robot vision part I,\" University of Stavanger, 2018. Compendium, CANVAS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ELE510')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0923cfb2878acf2827a8d43bc93fc53a1fd00daccffcd25e8da2187ecbca6197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
